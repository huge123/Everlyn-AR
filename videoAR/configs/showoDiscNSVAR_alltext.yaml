model_kwargs:
  ckpt_path: ''
  ignore_keys: []
  gpt_model: 'GPT-XL'
  gpt_type: 't2i'
  vocab_size: 8192
  num_classes: 1000
  cls_token_num: 129
  resid_dropout_p: 0.1
  ffn_dropout_p: 0.1
  token_dropout_p: 0.1 
  class_dropout_p: 0.1
  sample_every_n_latent_frames: 0
  hidden_dim: 2048 
  sample_size: 64
  caption_dim: 2048
  vae_dim: 8
  showo_pretrained_model_path: "checkpoints/showo/llm"


